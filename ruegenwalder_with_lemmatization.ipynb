{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aad4b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2c657c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"collection_A.pkl\", \"rb\") as f:\n",
    "    pickled_collection = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d248a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ruegi(lst):\n",
    "    tmp_lst = []\n",
    "    clean_lst = []\n",
    "    \n",
    "    for sublist in lst:\n",
    "        for item in sublist:\n",
    "            level_1 = re.sub(\"^[^\\\\n]*\\\\n\", \"\", item)\n",
    "            level_2 = re.sub(\"@.*?\\s\", \"\", level_1)\n",
    "            \n",
    "            if not re.search(\".*\\\\n\", level_2):\n",
    "                tmp_lst.append(level_2)\n",
    "            else:\n",
    "                matched_object = re.search(\".*\\\\n\", level_2)\n",
    "                matched_item = matched_object.group()\n",
    "                tmp_lst.append(matched_item)\n",
    "                \n",
    "    for comment in tmp_lst:\n",
    "        tmp_comment = re.sub(\"\\\\n\", \"\", comment)\n",
    "        clean_lst.append(tmp_comment)\n",
    "    \n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2dbf4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht l√§nger ab! üôåüèªü§© Holt euch den M√ºhlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil. üå≠üíö Mit etwas Gl√ºck zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein. üçÄ #R√ºgenwalderM√ºhle #M√ºhlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?ü§î‚òπ',\n",
       " 'Wie geilüî•üî•‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è',\n",
       " 'Wie macht ihr das eigentlich? ü§î Wie wir uns als traditioneller Wursthersteller f√ºr eine nachhaltige Zukunft und #Klimaneutralit√§t einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht. üåçüíö Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren. ‚ò∫Ô∏è Den Link zum Bericht findet ihr in der Bio! ‚úåüèª #R√ºgenwalderM√ºhle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? üòÄ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten ‚ù§ Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '‚ù§Ô∏è',\n",
       " 'Bitte vegan üå±',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. üò¢',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. üò¢',\n",
       " 'wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? üå± Mega Entwicklung. üëèüëè',\n",
       " 'mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tunüëèüëè',\n",
       " 'W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet üòÅ',\n",
       " 'Aufgepasst, liebe Social Media Welt! üåçüíö Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch. üöÄ Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise. ü§©üèÜ #R√ºgenwalderM√ºhle #M√ºhlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg √ºber vegetarisch?',\n",
       " 'Ich mag Euch f√ºr veggie, aber feiern w√ºrde ich Euch f√ºr vegan. Bekommt Ihr das hin? ü§©üí™üí™üí™',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_clean_lst = clean_ruegi(pickled_collection)\n",
    "a_clean_lst[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386b712",
   "metadata": {},
   "source": [
    "## Alternative Kommentarliste:\n",
    "\n",
    "Wenn das Topic Modeling keine sinnvollen Ergebnisse liefert, kann folgende Liste versuchsweise verwendet werden.\n",
    "Es wurden Einzelbeitr√§ge (also mit hoher Wahrscheinlichkeit Beitr√§ge, die entweder keine Benutzerantworten enthalten oder - wenn der Initialbeitrag des Autors fehlt - nur eine Antwort enthalten und somit eine geringe Relevanz aufweisen) entfernt.\n",
    "Sollte auch dies nicht zu aussagekr√§ftigten Ergebnissen f√ºhren, k√∂nnte die Originalliste wiederum um Beitr√§ge mit wenigen Antworten gefiltert werden (z.B. weniger als 5 Antworten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "264746ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['isa__90__\\nUnd wenn man kein tiktok hat?ü§î‚òπ\\n1 TagGef√§llt 2 MalAntworten',\n",
       "  'bentj_07\\nWie geilüî•üî•‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n1 TagAntworten'],\n",
       " ['sebastianpink96\\nDann mal weg mit dem Fleisch\\n1 Wo.Gef√§llt 13 MalAntworten',\n",
       "  'thinkvegande\\nWann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? üòÄ\\n1 Wo.Gef√§llt 33 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gef√§llt 1 MalAntworten',\n",
       "  'nina_joh93\\nGanz auf Fleisch verzichten ‚ù§ Ihr macht das so genial mit den Veggie Produkten!\\n1 Wo.Gef√§llt 17 MalAntworten',\n",
       "  'tascha4868\\n‚ù§Ô∏è\\n6 TageGef√§llt 1 MalAntworten',\n",
       "  'sab_koe\\nBitte vegan üå±\\n6 TageGef√§llt 6 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gef√§llt 5 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. üò¢\\n6 TageGef√§llt 1 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. üò¢\\n6 TageAntworten',\n",
       "  'curious.dev\\n@ruegenwaldermuehle wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? üå± Mega Entwicklung. üëèüëè\\n1 Wo.Gef√§llt 9 MalAntworten',\n",
       "  'succilady\\n@ruegenwaldermuehle mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tunüëèüëè\\n6 TageGef√§llt 5 MalAntworten',\n",
       "  'jaundiced_yellow\\n@ruegenwaldermuehle W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet üòÅ\\n1 Wo.Antworten']]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []\n",
    "for sublist in pickled_collection:\n",
    "    if len(sublist) > 1:\n",
    "        new_list.append(sublist)\n",
    "new_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e348148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11076"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_clean_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07643ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "\n",
    "def deEmojify(lst):\n",
    "    clean_lst = []\n",
    "    for item in lst:\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                                    \"]+\", flags = re.UNICODE)\n",
    "        tmp_item = regrex_pattern.sub(r'',item)\n",
    "        clean_lst.append(tmp_item)\n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dbc8c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht l√§nger ab!  Holt euch den M√ºhlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil.  Mit etwas Gl√ºck zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein.  #R√ºgenwalderM√ºhle #M√ºhlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?',\n",
       " 'Wie geil',\n",
       " 'Wie macht ihr das eigentlich?  Wie wir uns als traditioneller Wursthersteller f√ºr eine nachhaltige Zukunft und #Klimaneutralit√§t einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht.  Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren.  Den Link zum Bericht findet ihr in der Bio!  #R√ºgenwalderM√ºhle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten  Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '',\n",
       " 'Bitte vegan ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte?  Mega Entwicklung. ',\n",
       " 'mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tun',\n",
       " 'W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet ',\n",
       " 'Aufgepasst, liebe Social Media Welt!  Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch.  Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise.  #R√ºgenwalderM√ºhle #M√ºhlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg √ºber vegetarisch?',\n",
       " 'Ich mag Euch f√ºr veggie, aber feiern w√ºrde ich Euch f√ºr vegan. Bekommt Ihr das hin? ',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_ems = deEmojify(a_clean_lst)\n",
    "without_ems[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ceaf2693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>242 Wo.Gef√§llt 1 MalAntworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11076 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...\n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...\n",
       "11074                      242 Wo.Gef√§llt 1 MalAntworten\n",
       "11075                            Herzlichen Gl√ºckqunsch \n",
       "\n",
       "[11076 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'comments': without_ems})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64e1328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11069  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...\n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...\n",
       "11075                            Herzlichen Gl√ºckqunsch \n",
       "\n",
       "[8896 rows x 1 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bde4595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa801a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "decd8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "\n",
    "stopwords_custom = ['andere', 'der', 'weil', 'wieder', 'zwar', 'oder', 'so', 'solcher', 'unseres', 'doch', 'ihren', 'vor', 'ihm', 'hatte', 'muss', 'selbst', 'eurer', 'welchen', 'meine', 'was', 'werden', 'kann', 'einem', 'jedes', 'ihr', 'sie', 'sind', 'diesem', 'zu', 'jener', 'unser', 'sollte', 'manches', 'zur', 'diesen', 'allem', 'unserem', 'anderen', 'dieses', 'einen', 'hatten', 'einigem', 'hat', 'zwischen', 'zum', 'welche', 'dieser', 'nach', 'w√§hrend', 'wollte', 'bei', 'ich', 'dann', 'ihre', 'solchem', 'warst', 'das', 'meinen', 'sich', 'eure', 'einigen', 'deiner', 'keiner', 'da', 'meinem', 'k√∂nnte', 'seinen', 'dort', 'mein', 'wird', 'uns', 'am', 'derer', 'seine', 'er', 'da√ü', 'deines', 'w√ºrden', 'um', 'keines', 'musste', 'unsere', 'haben', 'weg', 'wo', 'wollen', 'dich', 'unter', 'in', 'ins', 'jeder', 'hier', 'von', 'dieselbe', 'dir', 'denn', 'diese', 'hab', 'indem', 'mit', 'einmal', 'allen', 'den', 'machen', 'ander', 'damit', 'durch', 'im', 'mich', 'dasselbe', 'euer', 'deinem', 'jenem', 'derselbe', 'dessen', 'alle', 'gewesen', 'aus', 'soll', 'jenen', 'welchem', 'anders', 'bin', 'bis', 'jene', 'solchen', 'du', 'ihres', 'demselben', 'als', 'will', 'wirst', 'war', 'jede', 'eures', 'dieselben', 'jedem', 'einige', 'eine', 'einiger', 'manche', 'seines', 'sein', 'denselben', 'noch', 'welcher', 'nur', 'mal', 'viel', 'ein', 'meiner', 'mancher', 'ihrer', 'desselben', 'ihrem', 'meines', 'dies', 'einer', 'jetzt', 'auch', 'f√ºr', 'wenn', 'solches', '√ºber', 'welches', 'ist', 'wie', 'es', 'anderm', 'deine', 'habe', 'wir', 'ohne', 'hin', 'dem', 'einiges', 'manchem', 'und', 'vom', 'w√ºrde', 'manchen', 'euch', 'solche', 'jenes', 'euren', 'aller', 'ihnen', 'eines', 'hinter', 'seinem', 'etwas', 'aber', 'kein', 'mir', 'dass', 'sondern', 'andern', 'anderes', 'unseren', 'dein', 'seiner', 'nun', 'jeden', 'anderer', 'man', 'weiter', 'sonst', 'keinem', 'alles', 'gegen', 'werde', 'bist', 'an', 'einig', 'ihn', 'auf', 'keine', 'des', 'eurem', 'derselben', 'anderem', 'dazu', 'k√∂nnen', 'waren', 'deinen', 'keinen', 'also', 'ob', 'die', 'une', 'retenter', 'gr', 'grad', 'tastes', 'texture', 'de', 'weekly', 'v√©g√©tal', 'break', 'bang', 'par', 'wheaty', 'pan', 'that', 'mai', 'hungry', 'additionally', 'after', 'cuisson', 'palette', 've', 'veau', 'vater', 'doutes', 'buns', 'ein', 'per', 'charcuteries', 'grad', 'haut', 'big', 'celle', 'certainement', 'contre', 'convincing', 'maie']\n",
    "\n",
    "def clean_text(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    stopwords_removed = [word for word in text_lower if word not in stopwords_custom]\n",
    "    lemmatized = [tagger.analyze(word)[0].lower() for word in stopwords_removed]\n",
    "    filtered = \" \".join(lemmatized)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"untouched_training_data.pkl\", \"rb\") as f:\n",
    "    review_data = pickle.load(f)\n",
    "\n",
    "review_data = review_data.assign(clean_comments = review_data[\"text\"].apply(lambda row: clean_text(row)))\n",
    "review_data\n",
    "\n",
    "with open(\"review_data_lemmatized.pkl\", \"wb\") as f:\n",
    "    pickle.dump(review_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dca5a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "      <td>wollen gewinn warten nicht lang ab holen m√ºhle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>machen eigentlich traditionell wursthersteller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "      <td>leckeres fr√ºhst√ºck aussehen schinkenspicker ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "      <td>m√ºhle werden er√∂ffnet m√ºhle wahrzeichen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "      <td>super m√ºhlenfest ja samstag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "      <td>herzlich gl√ºckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...   \n",
       "1                          Und wenn man kein tiktok hat?   \n",
       "2                                               Wie geil   \n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                           Dann mal weg mit dem Fleisch   \n",
       "...                                                  ...   \n",
       "11069  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...   \n",
       "11071                             Legga 288 Wo.Antworten   \n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...   \n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...   \n",
       "11075                            Herzlichen Gl√ºckqunsch    \n",
       "\n",
       "                                          clean_comments  \n",
       "0      wollen gewinn warten nicht lang ab holen m√ºhle...  \n",
       "1                                                 tiktok  \n",
       "2                                                   geil  \n",
       "3      machen eigentlich traditionell wursthersteller...  \n",
       "4                                                fleisch  \n",
       "...                                                  ...  \n",
       "11069  leckeres fr√ºhst√ºck aussehen schinkenspicker ru...  \n",
       "11071                                    legga antworten  \n",
       "11072            m√ºhle werden er√∂ffnet m√ºhle wahrzeichen  \n",
       "11073                        super m√ºhlenfest ja samstag  \n",
       "11075                               herzlich gl√ºckqunsch  \n",
       "\n",
       "[8896 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.assign(clean_comments = df[\"comments\"].apply(lambda row: clean_text(row)))\n",
    "#Making a copy for later use:\n",
    "fresh_df = df.copy()\n",
    "another_fresh_df = df.copy()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2b0bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fe2f3",
   "metadata": {},
   "source": [
    "## Test: Das SVC-Modell wird mit dem kompletten Review-Datensatz trainiert und mit dem neuen (R√ºgenwalder) Datensatz getestet\n",
    "\n",
    "Der TF-IDF-Vectorizer von Scikit-Learn wird als erstes an den kompletten (bereinigten) Text-Datensatz angepasst. Die Spalte \"clean_text\" wird in eine Sparse-Matrix √ºberf√ºhrt, der SVC-Classifier mit den in Vektoren √ºberf√ºhrten Kommentaren und den Kommentaren selbst (also hier \"Labels\" als tokinisierte Textbausteine) trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50c6e9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8346, 47326)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=0.3)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(review_data[\"clean_comments\"])\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c5fc2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "#classifier = LinearSVC()\n",
    "#calibrated_classifier = CalibratedClassifierCV(classifier)\n",
    "classifier.fit(X_train_tfidf, review_data.positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39ef9f",
   "metadata": {},
   "source": [
    "Wichtig ist hier darauf zu achten, den TF-IDF-Vectorizer nicht mit dem neuen Datensatz zu fitten, sondern vielmehr die neuen Kommentare mithilfe des Vektorisierers in eine f√ºr das Modell lesbare Zahlenmatrix zu √ºberf√ºhren - und zwar **mithilfe** des bereits angepassten Vektorisieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a15ec7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8896, 47326)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_ruegi = tfidf_vectorizer.transform(df.clean_comments)\n",
    "display(X_test_ruegi.shape)\n",
    "\n",
    "prediction_model_only = classifier.predict(X_test_ruegi)\n",
    "#prediction_model_only = calibrated_classifier.predict(X_test_ruegi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db3d2b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "      <td>wollen gewinn warten nicht lang ab holen m√ºhle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>machen eigentlich traditionell wursthersteller...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "      <td>leckeres fr√ºhst√ºck aussehen schinkenspicker ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antworten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "      <td>m√ºhle werden er√∂ffnet m√ºhle wahrzeichen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "      <td>super m√ºhlenfest ja samstag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "      <td>herzlich gl√ºckqunsch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...   \n",
       "1                          Und wenn man kein tiktok hat?   \n",
       "2                                               Wie geil   \n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                           Dann mal weg mit dem Fleisch   \n",
       "...                                                  ...   \n",
       "11069  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...   \n",
       "11071                             Legga 288 Wo.Antworten   \n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...   \n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...   \n",
       "11075                            Herzlichen Gl√ºckqunsch    \n",
       "\n",
       "                                          clean_comments  prediction  \n",
       "0      wollen gewinn warten nicht lang ab holen m√ºhle...           1  \n",
       "1                                                 tiktok           1  \n",
       "2                                                   geil           1  \n",
       "3      machen eigentlich traditionell wursthersteller...           1  \n",
       "4                                                fleisch           1  \n",
       "...                                                  ...         ...  \n",
       "11069  leckeres fr√ºhst√ºck aussehen schinkenspicker ru...           1  \n",
       "11071                                    legga antworten           1  \n",
       "11072            m√ºhle werden er√∂ffnet m√ºhle wahrzeichen           1  \n",
       "11073                        super m√ºhlenfest ja samstag           1  \n",
       "11075                               herzlich gl√ºckqunsch           1  \n",
       "\n",
       "[8896 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0: negativ, 1: positiv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fresh_df = fresh_df.assign(prediction = prediction_model_only)\n",
    "display(fresh_df)\n",
    "display(\"0: negativ, 1: positiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4c7cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline.csv\")\n",
    "fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline_SVC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed0be2",
   "metadata": {},
   "source": [
    "Zum einfacheren Vergleich werden die kategorisierten Datens√§tze als CSV exportiert. Tats√§chlich lassen sich kleinere Unterschiede zwischen den Einsch√§tzungen der unterschiedlich trainierten Modelle feststellen. Das SVC-Modell mit dem kompletten Review-Datensatz als Trainings-Material scheint geringf√ºgig bessere Entscheidungen zu treffen.\n",
    "Dies ist hier im n√§chsten Schritt statistisch zu zeigen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7c593",
   "metadata": {},
   "source": [
    "Die G√ºte des \"alten\" Models bleibt unver√§ndert:\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       0.79      0.60      0.68       128\n",
    "               1       0.93      0.97      0.95       707\n",
    "\n",
    "        accuracy                           0.91       835\n",
    "       macro avg       0.86      0.79      0.82       835\n",
    "    weighted avg       0.91      0.91      0.91       835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db99fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_of_x = calibrated_classifier.predict(X_train_tfidf)\n",
    "prediction_of_x = classifier.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "592e3d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1388\n",
      "           1       0.98      1.00      0.99      6958\n",
      "\n",
      "    accuracy                           0.99      8346\n",
      "   macro avg       0.99      0.96      0.97      8346\n",
      "weighted avg       0.99      0.99      0.98      8346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(review_data.positive, prediction_of_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d52bd882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8346x47326 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 115714 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "990dc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(max_df = 0.3, min_df = 7, ngram_range = (1, 2))), ('clf', SVC(kernel = 'sigmoid'))])\n",
    "#As of now the GridSearch was useless, results are less accurate!\n",
    "#The tested GridParams should be modified, C is not useful, kernel may not be useful, max_iter is def not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8db1b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.3, max_features=None,\n",
       "                                 min_df=7, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='sigmoid', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(review_data.clean_comments, review_data.positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "13321ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_new_pipeline = pipeline.predict(df.clean_comments)\n",
    "another_fresh_df = another_fresh_df.assign(prediction = prediction_new_pipeline)\n",
    "another_fresh_df\n",
    "another_fresh_df.to_csv(\"ruegi_comments_new_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0134af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': np.arange(0.3, 0.8, 0.1),\n",
    "    'vect__min_df': np.arange(1, 8, 1),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'vect__norm': ('l1', 'l2', None),\n",
    "    'clf__max_iter': (10, 50, 80),\n",
    "    'clf__kernel':('linear', 'rbf', 'sigmoid'),\n",
    "    'clf__C':[1, 10]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07758451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#grid_search = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1)\n",
    "#grid_search.fit(clean_review_data.clean_text, clean_review_data.positive)\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1399868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob_de import TextBlobDE as TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e773a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "      <td>wollen gewinn warten nicht lang ab holen m√ºhle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>machen eigentlich traditionell wursthersteller...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8891</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "      <td>leckeres fr√ºhst√ºck aussehen schinkenspicker ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antworten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "      <td>m√ºhle werden er√∂ffnet m√ºhle wahrzeichen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "      <td>super m√ºhlenfest ja samstag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "      <td>herzlich gl√ºckqunsch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  \\\n",
       "0     Ihr wollt gewinnen? Dann wartet nicht l√§nger a...   \n",
       "1                         Und wenn man kein tiktok hat?   \n",
       "2                                              Wie geil   \n",
       "3     Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                          Dann mal weg mit dem Fleisch   \n",
       "...                                                 ...   \n",
       "8891  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...   \n",
       "8892                             Legga 288 Wo.Antworten   \n",
       "8893  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...   \n",
       "8894  War super euer m√ºhlenfest ;) wir waren ja den ...   \n",
       "8895                            Herzlichen Gl√ºckqunsch    \n",
       "\n",
       "                                         clean_comments  prediction  \n",
       "0     wollen gewinn warten nicht lang ab holen m√ºhle...           1  \n",
       "1                                                tiktok           1  \n",
       "2                                                  geil           1  \n",
       "3     machen eigentlich traditionell wursthersteller...           1  \n",
       "4                                               fleisch           1  \n",
       "...                                                 ...         ...  \n",
       "8891  leckeres fr√ºhst√ºck aussehen schinkenspicker ru...           1  \n",
       "8892                                    legga antworten           1  \n",
       "8893            m√ºhle werden er√∂ffnet m√ºhle wahrzeichen           1  \n",
       "8894                        super m√ºhlenfest ja samstag           1  \n",
       "8895                               herzlich gl√ºckqunsch           1  \n",
       "\n",
       "[8896 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruegi_comments = pd.read_csv(\"ruegi_comments_new_pipeline.csv\")\n",
    "ruegi_comments = ruegi_comments.drop([\"Unnamed: 0\"], axis=1)\n",
    "fresh_copy = ruegi_comments.copy()\n",
    "fresh_copy[\"comments\"] = fresh_copy[\"comments\"].astype(str)\n",
    "fresh_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cd89009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>prediction</th>\n",
       "      <th>blob_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "      <td>wollen gewinn warten nicht lang ab holen m√ºhle...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>machen eigentlich traditionell wursthersteller...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8891</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "      <td>leckeres fr√ºhst√ºck aussehen schinkenspicker ru...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8892</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antworten</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8893</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "      <td>m√ºhle werden er√∂ffnet m√ºhle wahrzeichen</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8894</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "      <td>super m√ºhlenfest ja samstag</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "      <td>herzlich gl√ºckqunsch</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  \\\n",
       "0     Ihr wollt gewinnen? Dann wartet nicht l√§nger a...   \n",
       "1                         Und wenn man kein tiktok hat?   \n",
       "2                                              Wie geil   \n",
       "3     Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                          Dann mal weg mit dem Fleisch   \n",
       "...                                                 ...   \n",
       "8891  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...   \n",
       "8892                             Legga 288 Wo.Antworten   \n",
       "8893  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...   \n",
       "8894  War super euer m√ºhlenfest ;) wir waren ja den ...   \n",
       "8895                            Herzlichen Gl√ºckqunsch    \n",
       "\n",
       "                                         clean_comments  prediction  \\\n",
       "0     wollen gewinn warten nicht lang ab holen m√ºhle...           1   \n",
       "1                                                tiktok           1   \n",
       "2                                                  geil           1   \n",
       "3     machen eigentlich traditionell wursthersteller...           1   \n",
       "4                                               fleisch           1   \n",
       "...                                                 ...         ...   \n",
       "8891  leckeres fr√ºhst√ºck aussehen schinkenspicker ru...           1   \n",
       "8892                                    legga antworten           1   \n",
       "8893            m√ºhle werden er√∂ffnet m√ºhle wahrzeichen           1   \n",
       "8894                        super m√ºhlenfest ja samstag           1   \n",
       "8895                               herzlich gl√ºckqunsch           1   \n",
       "\n",
       "      blob_prediction  \n",
       "0                0.23  \n",
       "1                0.00  \n",
       "2                0.70  \n",
       "3                0.06  \n",
       "4                0.00  \n",
       "...               ...  \n",
       "8891             0.00  \n",
       "8892             0.00  \n",
       "8893             0.00  \n",
       "8894             0.00  \n",
       "8895             1.00  \n",
       "\n",
       "[8896 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_copy = fresh_copy.assign(blob_prediction = fresh_copy[\"comments\"].apply(lambda row: TextBlob(row).sentiment[0]))\n",
    "fresh_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa9a2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_copy.to_csv(\"ruegie_comments_with_blob_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a742fb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73839/676754649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeaveOneOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcross_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    386\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    228\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    229\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 230\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    231\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    232\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             libsvm_sparse.libsvm_sparse_train(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mkernel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/datascience/env_svc_0222/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Takes a long time!\n",
    "loo = LeaveOneOut()\n",
    "#cross_validation = cross_val_score(classifier, X_train_tfidf, review_data.positive, cv = loo, scoring='accuracy')\n",
    "#cross_validation.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5edae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
