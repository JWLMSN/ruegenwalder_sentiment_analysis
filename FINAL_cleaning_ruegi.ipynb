{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aad4b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2c657c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"collection_A.pkl\", \"rb\") as f:\n",
    "    pickled_collection = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d248a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ruegi(lst):\n",
    "    tmp_lst = []\n",
    "    clean_lst = []\n",
    "    \n",
    "    for sublist in lst:\n",
    "        for item in sublist:\n",
    "            level_1 = re.sub(\"^[^\\\\n]*\\\\n\", \"\", item)\n",
    "            level_2 = re.sub(\"@.*?\\s\", \"\", level_1)\n",
    "            \n",
    "            if not re.search(\".*\\\\n\", level_2):\n",
    "                tmp_lst.append(level_2)\n",
    "            else:\n",
    "                matched_object = re.search(\".*\\\\n\", level_2)\n",
    "                matched_item = matched_object.group()\n",
    "                tmp_lst.append(matched_item)\n",
    "                \n",
    "    for comment in tmp_lst:\n",
    "        tmp_comment = re.sub(\"\\\\n\", \"\", comment)\n",
    "        clean_lst.append(tmp_comment)\n",
    "    \n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2dbf4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht länger ab! 🙌🏻🤩 Holt euch den Mühlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil. 🌭💚 Mit etwas Glück zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein. 🍀 #RügenwalderMühle #MühlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?🤔☹',\n",
       " 'Wie geil🔥🔥❤️❤️❤️❤️',\n",
       " 'Wie macht ihr das eigentlich? 🤔 Wie wir uns als traditioneller Wursthersteller für eine nachhaltige Zukunft und #Klimaneutralität einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht. 🌍💚 Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren. ☺️ Den Link zum Bericht findet ihr in der Bio! ✌🏻 #RügenwalderMühle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? 😀',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten ❤ Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '❤️',\n",
       " 'Bitte vegan 🌱',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. 😢',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. 😢',\n",
       " 'wenn ihr euch für Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? 🌱 Mega Entwicklung. 👏👏',\n",
       " 'mich würde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufhört und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einfährt, wird ja durch die Zahlen immer wieder belegt und somit könnt ihr dann tatsächlich mehr für das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose töten von Lebewesen tun👏👏',\n",
       " 'Würde mich auch freuen, wenn ihr mal in meine DMs sliden würdet 😁',\n",
       " 'Aufgepasst, liebe Social Media Welt! 🌍💚 Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch. 🚀 Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise. 🤩🏆 #RügenwalderMühle #MühlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg über vegetarisch?',\n",
       " 'Ich mag Euch für veggie, aber feiern würde ich Euch für vegan. Bekommt Ihr das hin? 🤩💪💪💪',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_clean_lst = clean_ruegi(pickled_collection)\n",
    "a_clean_lst[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386b712",
   "metadata": {},
   "source": [
    "## Alternative Kommentarliste:\n",
    "\n",
    "Wenn das Topic Modeling keine sinnvollen Ergebnisse liefert, kann folgende Liste versuchsweise verwendet werden.\n",
    "Es wurden Einzelbeiträge (also mit hoher Wahrscheinlichkeit Beiträge, die entweder keine Benutzerantworten enthalten oder - wenn der Initialbeitrag des Autors fehlt - nur eine Antwort enthalten und somit eine geringe Relevanz aufweisen) entfernt.\n",
    "Sollte auch dies nicht zu aussagekräftigten Ergebnissen führen, könnte die Originalliste wiederum um Beiträge mit wenigen Antworten gefiltert werden (z.B. weniger als 5 Antworten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "264746ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['isa__90__\\nUnd wenn man kein tiktok hat?🤔☹\\n1 TagGefällt 2 MalAntworten',\n",
       "  'bentj_07\\nWie geil🔥🔥❤️❤️❤️❤️\\n1 TagAntworten'],\n",
       " ['sebastianpink96\\nDann mal weg mit dem Fleisch\\n1 Wo.Gefällt 13 MalAntworten',\n",
       "  'thinkvegande\\nWann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? 😀\\n1 Wo.Gefällt 33 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gefällt 1 MalAntworten',\n",
       "  'nina_joh93\\nGanz auf Fleisch verzichten ❤ Ihr macht das so genial mit den Veggie Produkten!\\n1 Wo.Gefällt 17 MalAntworten',\n",
       "  'tascha4868\\n❤️\\n6 TageGefällt 1 MalAntworten',\n",
       "  'sab_koe\\nBitte vegan 🌱\\n6 TageGefällt 6 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gefällt 5 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. 😢\\n6 TageGefällt 1 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. 😢\\n6 TageAntworten',\n",
       "  'curious.dev\\n@ruegenwaldermuehle wenn ihr euch für Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? 🌱 Mega Entwicklung. 👏👏\\n1 Wo.Gefällt 9 MalAntworten',\n",
       "  'succilady\\n@ruegenwaldermuehle mich würde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufhört und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einfährt, wird ja durch die Zahlen immer wieder belegt und somit könnt ihr dann tatsächlich mehr für das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose töten von Lebewesen tun👏👏\\n6 TageGefällt 5 MalAntworten',\n",
       "  'jaundiced_yellow\\n@ruegenwaldermuehle Würde mich auch freuen, wenn ihr mal in meine DMs sliden würdet 😁\\n1 Wo.Antworten']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []\n",
    "for sublist in pickled_collection:\n",
    "    if len(sublist) > 1:\n",
    "        new_list.append(sublist)\n",
    "new_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e348148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11076"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_clean_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "07643ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "\n",
    "def deEmojify(lst):\n",
    "    clean_lst = []\n",
    "    for item in lst:\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                                    \"]+\", flags = re.UNICODE)\n",
    "        tmp_item = regrex_pattern.sub(r'',item)\n",
    "        clean_lst.append(tmp_item)\n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbc8c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht länger ab!  Holt euch den Mühlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil.  Mit etwas Glück zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein.  #RügenwalderMühle #MühlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?',\n",
       " 'Wie geil',\n",
       " 'Wie macht ihr das eigentlich?  Wie wir uns als traditioneller Wursthersteller für eine nachhaltige Zukunft und #Klimaneutralität einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht.  Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren.  Den Link zum Bericht findet ihr in der Bio!  #RügenwalderMühle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten  Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '',\n",
       " 'Bitte vegan ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'wenn ihr euch für Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte?  Mega Entwicklung. ',\n",
       " 'mich würde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufhört und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einfährt, wird ja durch die Zahlen immer wieder belegt und somit könnt ihr dann tatsächlich mehr für das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose töten von Lebewesen tun',\n",
       " 'Würde mich auch freuen, wenn ihr mal in meine DMs sliden würdet ',\n",
       " 'Aufgepasst, liebe Social Media Welt!  Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch.  Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise.  #RügenwalderMühle #MühlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg über vegetarisch?',\n",
       " 'Ich mag Euch für veggie, aber feiern würde ich Euch für vegan. Bekommt Ihr das hin? ',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_ems = deEmojify(a_clean_lst)\n",
    "without_ems[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ceaf2693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht länger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer mühlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>242 Wo.Gefällt 1 MalAntworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Glückqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11076 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht länger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...\n",
       "11073  War super euer mühlenfest ;) wir waren ja den ...\n",
       "11074                      242 Wo.Gefällt 1 MalAntworten\n",
       "11075                            Herzlichen Glückqunsch \n",
       "\n",
       "[11076 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'comments': without_ems})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64e1328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht länger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Frühstück aussehen :-) #Schin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer mühlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Glückqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht länger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11069  So muss leckeres Frühstück aussehen :-) #Schin...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...\n",
       "11073  War super euer mühlenfest ;) wir waren ja den ...\n",
       "11075                            Herzlichen Glückqunsch \n",
       "\n",
       "[8896 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bde4595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aa801a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "decd8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht länger a...</td>\n",
       "      <td>wollt gewinn wartet nicht lang ab holt muhl sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>macht eigent traditionell wurstherstell nachha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Frühstück aussehen :-) #Schin...</td>\n",
       "      <td>leck fruhstuck ausseh schinkenspick ruegenwald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antwort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...</td>\n",
       "      <td>muhl wurd eroffnet muhl wahrzeich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer mühlenfest ;) wir waren ja den ...</td>\n",
       "      <td>sup muhlenf ja samstag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Glückqunsch</td>\n",
       "      <td>herzlich gluckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht länger a...   \n",
       "1                          Und wenn man kein tiktok hat?   \n",
       "2                                               Wie geil   \n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                           Dann mal weg mit dem Fleisch   \n",
       "...                                                  ...   \n",
       "11069  So muss leckeres Frühstück aussehen :-) #Schin...   \n",
       "11071                             Legga 288 Wo.Antworten   \n",
       "11072  Mai 2013: Die Mühle wurde eröffnet! :-) #Mühle...   \n",
       "11073  War super euer mühlenfest ;) wir waren ja den ...   \n",
       "11075                            Herzlichen Glückqunsch    \n",
       "\n",
       "                                          clean_comments  \n",
       "0      wollt gewinn wartet nicht lang ab holt muhl sn...  \n",
       "1                                                 tiktok  \n",
       "2                                                   geil  \n",
       "3      macht eigent traditionell wurstherstell nachha...  \n",
       "4                                                fleisch  \n",
       "...                                                  ...  \n",
       "11069     leck fruhstuck ausseh schinkenspick ruegenwald  \n",
       "11071                                      legga antwort  \n",
       "11072                  muhl wurd eroffnet muhl wahrzeich  \n",
       "11073                             sup muhlenf ja samstag  \n",
       "11075                               herzlich gluckqunsch  \n",
       "\n",
       "[8896 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "\n",
    "stopwords_custom = ['andere', 'der', 'weil', 'wieder', 'zwar', 'oder', 'so', 'solcher', 'unseres', 'doch', 'ihren', 'vor', 'ihm', 'hatte', 'muss', 'selbst', 'eurer', 'welchen', 'meine', 'was', 'werden', 'kann', 'einem', 'jedes', 'ihr', 'sie', 'sind', 'diesem', 'zu', 'jener', 'unser', 'sollte', 'manches', 'zur', 'diesen', 'allem', 'unserem', 'anderen', 'dieses', 'einen', 'hatten', 'einigem', 'hat', 'zwischen', 'zum', 'welche', 'dieser', 'nach', 'während', 'wollte', 'bei', 'ich', 'dann', 'ihre', 'solchem', 'warst', 'das', 'meinen', 'sich', 'eure', 'einigen', 'deiner', 'keiner', 'da', 'meinem', 'könnte', 'seinen', 'dort', 'mein', 'wird', 'uns', 'am', 'derer', 'seine', 'er', 'daß', 'deines', 'würden', 'um', 'keines', 'musste', 'unsere', 'haben', 'weg', 'wo', 'wollen', 'dich', 'unter', 'in', 'ins', 'jeder', 'hier', 'von', 'dieselbe', 'dir', 'denn', 'diese', 'hab', 'indem', 'mit', 'einmal', 'allen', 'den', 'machen', 'ander', 'damit', 'durch', 'im', 'mich', 'dasselbe', 'euer', 'deinem', 'jenem', 'derselbe', 'dessen', 'alle', 'gewesen', 'aus', 'soll', 'jenen', 'welchem', 'anders', 'bin', 'bis', 'jene', 'solchen', 'du', 'ihres', 'demselben', 'als', 'will', 'wirst', 'war', 'jede', 'eures', 'dieselben', 'jedem', 'einige', 'eine', 'einiger', 'manche', 'seines', 'sein', 'denselben', 'noch', 'welcher', 'nur', 'mal', 'viel', 'ein', 'meiner', 'mancher', 'ihrer', 'desselben', 'ihrem', 'meines', 'dies', 'einer', 'jetzt', 'auch', 'für', 'wenn', 'solches', 'über', 'welches', 'ist', 'wie', 'es', 'anderm', 'deine', 'habe', 'wir', 'ohne', 'hin', 'dem', 'einiges', 'manchem', 'und', 'vom', 'würde', 'manchen', 'euch', 'solche', 'jenes', 'euren', 'aller', 'ihnen', 'eines', 'hinter', 'seinem', 'etwas', 'aber', 'kein', 'mir', 'dass', 'sondern', 'andern', 'anderes', 'unseren', 'dein', 'seiner', 'nun', 'jeden', 'anderer', 'man', 'weiter', 'sonst', 'keinem', 'alles', 'gegen', 'werde', 'bist', 'an', 'einig', 'ihn', 'auf', 'keine', 'des', 'eurem', 'derselben', 'anderem', 'dazu', 'können', 'waren', 'deinen', 'keinen', 'also', 'ob', 'die', 'une', 'retenter', 'gr', 'grad', 'tastes', 'texture', 'de', 'weekly', 'végétal', 'break', 'bang', 'par', 'wheaty', 'pan', 'that', 'mai', 'hungry', 'additionally', 'after', 'cuisson', 'palette', 've', 'veau', 'vater', 'doutes', 'buns', 'ein', 'per', 'charcuteries', 'grad', 'haut', 'big', 'celle', 'certainement', 'contre', 'convincing', 'maie']\n",
    "\n",
    "def clean_text(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    stopwords_removed = [word for word in text_lower if word not in stopwords_custom]\n",
    "    stemmed_words = [stemmer.stem(word) for word in stopwords_removed]\n",
    "    filtered = \" \".join(stemmed_words)\n",
    "    return filtered\n",
    "\n",
    "df = df.assign(clean_comments = df[\"comments\"].apply(lambda row: clean_text(row)))\n",
    "#Making a copy for later use:\n",
    "fresh_df = df.copy()\n",
    "another_fresh_df = df.copy()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dca5a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = df[df.comments.str.contains(\"vegan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "927268be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wann gibt es endlich den veganen Schinken aus ...</td>\n",
       "      <td>wann gibt endlich vegan schink vegan cordon bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitte vegan</td>\n",
       "      <td>bitt vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wenn ihr euch für Menschen, Tiere und die Umwe...</td>\n",
       "      <td>mensch tier umwelt engagiert veganisiert endli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mich würde es eher interessieren, wann ihr das...</td>\n",
       "      <td>eher interessi wann traditionell tierisch endl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Warum nicht vegan? Wozu immer erst der Umweg ü...</td>\n",
       "      <td>warum nicht vegan wozu imm erst umweg vegetar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Ich finde es toll, dass ihr nun auch vegan und...</td>\n",
       "      <td>find toll vegan vegetar produziert helft sehr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>Könnt ihr noch mehr raus bringen veggi und veg...</td>\n",
       "      <td>konnt mehr raus bring veggi vegan freund ess i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>Deshalb lebe ich seit einiger Zeit jetzt auch ...</td>\n",
       "      <td>deshalb leb seit zeit vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>Macht doch bittebittebitte eure vegetarische W...</td>\n",
       "      <td>macht bittebittebitt vegetar wurst vegan war s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Und Mettwurst als vegetarische bzw. vegane Alt...</td>\n",
       "      <td>mettwurst vegetar bzw vegan alternativ war sup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "5      Wann gibt es endlich den veganen Schinken aus ...   \n",
       "9                                           Bitte vegan    \n",
       "13     wenn ihr euch für Menschen, Tiere und die Umwe...   \n",
       "14     mich würde es eher interessieren, wann ihr das...   \n",
       "17     Warum nicht vegan? Wozu immer erst der Umweg ü...   \n",
       "...                                                  ...   \n",
       "10727  Ich finde es toll, dass ihr nun auch vegan und...   \n",
       "10728  Könnt ihr noch mehr raus bringen veggi und veg...   \n",
       "10761  Deshalb lebe ich seit einiger Zeit jetzt auch ...   \n",
       "10801  Macht doch bittebittebitte eure vegetarische W...   \n",
       "10802  Und Mettwurst als vegetarische bzw. vegane Alt...   \n",
       "\n",
       "                                          clean_comments  \n",
       "5      wann gibt endlich vegan schink vegan cordon bl...  \n",
       "9                                             bitt vegan  \n",
       "13     mensch tier umwelt engagiert veganisiert endli...  \n",
       "14     eher interessi wann traditionell tierisch endl...  \n",
       "17         warum nicht vegan wozu imm erst umweg vegetar  \n",
       "...                                                  ...  \n",
       "10727  find toll vegan vegetar produziert helft sehr ...  \n",
       "10728  konnt mehr raus bring veggi vegan freund ess i...  \n",
       "10761                        deshalb leb seit zeit vegan  \n",
       "10801  macht bittebittebitt vegetar wurst vegan war s...  \n",
       "10802     mettwurst vegetar bzw vegan alternativ war sup  \n",
       "\n",
       "[1857 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65bb77",
   "metadata": {},
   "source": [
    "## Klassifizierungsversuch mithilfe des trainierten SVC-Modells\n",
    "\n",
    "1. \"clean_comments\" sind die neuen Test-Daten\n",
    "2. predict-Funktion des Models zeigt Ergebnis der Klassifizierung\n",
    "3. Ausgabe der sortierten \"clean_comments\" (positiv/negativ)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2b0bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "with open(\"trained_pipeline.pkl\", \"rb\") as f:\n",
    "    trained_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1da119cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trained_pipeline.predict(vegan[\"clean_comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7815ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = vegan.assign(prediction = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95022025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wann gibt es endlich den veganen Schinken aus ...</td>\n",
       "      <td>wann gibt endlich vegan schink vegan cordon bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitte vegan</td>\n",
       "      <td>bitt vegan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wenn ihr euch für Menschen, Tiere und die Umwe...</td>\n",
       "      <td>mensch tier umwelt engagiert veganisiert endli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mich würde es eher interessieren, wann ihr das...</td>\n",
       "      <td>eher interessi wann traditionell tierisch endl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Warum nicht vegan? Wozu immer erst der Umweg ü...</td>\n",
       "      <td>warum nicht vegan wozu imm erst umweg vegetar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Ich finde es toll, dass ihr nun auch vegan und...</td>\n",
       "      <td>find toll vegan vegetar produziert helft sehr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>Könnt ihr noch mehr raus bringen veggi und veg...</td>\n",
       "      <td>konnt mehr raus bring veggi vegan freund ess i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>Deshalb lebe ich seit einiger Zeit jetzt auch ...</td>\n",
       "      <td>deshalb leb seit zeit vegan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>Macht doch bittebittebitte eure vegetarische W...</td>\n",
       "      <td>macht bittebittebitt vegetar wurst vegan war s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Und Mettwurst als vegetarische bzw. vegane Alt...</td>\n",
       "      <td>mettwurst vegetar bzw vegan alternativ war sup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "5      Wann gibt es endlich den veganen Schinken aus ...   \n",
       "9                                           Bitte vegan    \n",
       "13     wenn ihr euch für Menschen, Tiere und die Umwe...   \n",
       "14     mich würde es eher interessieren, wann ihr das...   \n",
       "17     Warum nicht vegan? Wozu immer erst der Umweg ü...   \n",
       "...                                                  ...   \n",
       "10727  Ich finde es toll, dass ihr nun auch vegan und...   \n",
       "10728  Könnt ihr noch mehr raus bringen veggi und veg...   \n",
       "10761  Deshalb lebe ich seit einiger Zeit jetzt auch ...   \n",
       "10801  Macht doch bittebittebitte eure vegetarische W...   \n",
       "10802  Und Mettwurst als vegetarische bzw. vegane Alt...   \n",
       "\n",
       "                                          clean_comments  prediction  \n",
       "5      wann gibt endlich vegan schink vegan cordon bl...           1  \n",
       "9                                             bitt vegan           1  \n",
       "13     mensch tier umwelt engagiert veganisiert endli...           1  \n",
       "14     eher interessi wann traditionell tierisch endl...           0  \n",
       "17         warum nicht vegan wozu imm erst umweg vegetar           1  \n",
       "...                                                  ...         ...  \n",
       "10727  find toll vegan vegetar produziert helft sehr ...           1  \n",
       "10728  konnt mehr raus bring veggi vegan freund ess i...           1  \n",
       "10761                        deshalb leb seit zeit vegan           1  \n",
       "10801  macht bittebittebitt vegetar wurst vegan war s...           1  \n",
       "10802     mettwurst vegetar bzw vegan alternativ war sup           1  \n",
       "\n",
       "[1857 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0: negativ, 1: positiv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(vegan)\n",
    "display(\"0: negativ, 1: positiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2bcaec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_positive_predicted = vegan[vegan.prediction == 1]\n",
    "vegan_negative_predicted = vegan[vegan.prediction == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "926ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan.to_csv(\"ruegi_vegan_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e9c2af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_prediction = trained_pipeline.predict(df[\"clean_comments\"])\n",
    "df = df.assign(prediction = complete_df_prediction)\n",
    "df.to_csv(\"ruegi_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fe2f3",
   "metadata": {},
   "source": [
    "## Test: Das SVC-Modell wird mit dem kompletten Review-Datensatz trainiert und mit dem neuen (Rügenwalder) Datensatz getestet\n",
    "\n",
    "Der TF-IDF-Vectorizer von Scikit-Learn wird als erstes an den kompletten (bereinigten) Text-Datensatz angepasst. Die Spalte \"clean_text\" wird in eine Sparse-Matrix überführt, der SVC-Classifier mit den in Vektoren überführten Kommentaren und den Kommentaren selbst (also hier \"Labels\" als tokinisierte Textbausteine) trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac84a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuckergehalt</td>\n",
       "      <td>1</td>\n",
       "      <td>zuckergehalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gehören in jeden veganen Haushalt!</td>\n",
       "      <td>1</td>\n",
       "      <td>gehor vegan haushalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schon ein Klassiker...</td>\n",
       "      <td>1</td>\n",
       "      <td>schon klassik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "      <td>sup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "      <td>sup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8341</th>\n",
       "      <td>Geschmack ist pappig und maggiartig, die Konsi...</td>\n",
       "      <td>0</td>\n",
       "      <td>geschmack pappig maggiart konsistenz klebrig p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>Da scheiden sich sie Geister. So meiner ist er...</td>\n",
       "      <td>0</td>\n",
       "      <td>scheid geist nicht probi test liebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>Richtig lecker, aber leider zu trocken. Da geh...</td>\n",
       "      <td>0</td>\n",
       "      <td>richtig leck leid trock geht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>Die Muffins haben zwar eine guten Preis, waren...</td>\n",
       "      <td>0</td>\n",
       "      <td>muffin gut preis trock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>Die helle Muffin Variante mit Schokostücken vo...</td>\n",
       "      <td>0</td>\n",
       "      <td>hell muffin variant schokostuck veganz leck sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  positive  \\\n",
       "0                                          Zuckergehalt         1   \n",
       "1                    Gehören in jeden veganen Haushalt!         1   \n",
       "2                                Schon ein Klassiker...         1   \n",
       "3                                                Super!         1   \n",
       "4                                                Super!         1   \n",
       "...                                                 ...       ...   \n",
       "8341  Geschmack ist pappig und maggiartig, die Konsi...         0   \n",
       "8342  Da scheiden sich sie Geister. So meiner ist er...         0   \n",
       "8343  Richtig lecker, aber leider zu trocken. Da geh...         0   \n",
       "8344  Die Muffins haben zwar eine guten Preis, waren...         0   \n",
       "8345  Die helle Muffin Variante mit Schokostücken vo...         0   \n",
       "\n",
       "                                             clean_text  \n",
       "0                                          zuckergehalt  \n",
       "1                                  gehor vegan haushalt  \n",
       "2                                         schon klassik  \n",
       "3                                                   sup  \n",
       "4                                                   sup  \n",
       "...                                                 ...  \n",
       "8341  geschmack pappig maggiart konsistenz klebrig p...  \n",
       "8342                scheid geist nicht probi test liebe  \n",
       "8343                       richtig leck leid trock geht  \n",
       "8344                             muffin gut preis trock  \n",
       "8345  hell muffin variant schokostuck veganz leck sa...  \n",
       "\n",
       "[8302 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"cleaned_training_data.pkl\", \"rb\") as f:\n",
    "    clean_review_data = pickle.load(f)\n",
    "clean_review_data[\"text\"].replace(\"\", np.nan, inplace=True)\n",
    "clean_review_data = clean_review_data[clean_review_data[\"text\"].notna()]\n",
    "#new_review_data = clean_review_data\n",
    "clean_review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c1512e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_letters(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    filtered = \" \".join(text_lower)\n",
    "    return filtered\n",
    "\n",
    "clean_review_data = clean_review_data.assign(langdetect = clean_review_data[\"text\"].apply(lambda row: remove_non_letters(row)))\n",
    "clean_review_data[\"langdetect\"].replace(\"\", np.nan, inplace=True)\n",
    "clean_review_data = clean_review_data[clean_review_data[\"langdetect\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e670ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "detect(clean_review_data[\"text\"][888])\n",
    "german_review_data = clean_review_data[clean_review_data[\"langdetect\"].apply(lambda row: detect(row) == \"de\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_cp_german_review_data = german_review_data.copy()\n",
    "display(clean_review_data.info())\n",
    "display(german_review_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=0.3)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(german_review_data[\"clean_text\"])\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "#classifier = LinearSVC()\n",
    "#calibrated_classifier = CalibratedClassifierCV(classifier)\n",
    "classifier.fit(X_train_tfidf, german_review_data.positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39ef9f",
   "metadata": {},
   "source": [
    "Wichtig ist hier darauf zu achten, den TF-IDF-Vectorizer nicht mit dem neuen Datensatz zu fitten, sondern vielmehr die neuen Kommentare mithilfe des Vektorisierers in eine für das Modell lesbare Zahlenmatrix zu überführen - und zwar **mithilfe** des bereits angepassten Vektorisieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ec7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ruegi = tfidf_vectorizer.transform(df.clean_comments)\n",
    "display(X_test_ruegi.shape)\n",
    "\n",
    "prediction_model_only = classifier.predict(X_test_ruegi)\n",
    "#prediction_model_only = calibrated_classifier.predict(X_test_ruegi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_df = fresh_df.assign(prediction = prediction_model_only)\n",
    "display(fresh_df)\n",
    "display(\"0: negativ, 1: positiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline.csv\")\n",
    "fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline_SVC_STEMMED_VERSION.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed0be2",
   "metadata": {},
   "source": [
    "Zum einfacheren Vergleich werden die kategorisierten Datensätze als CSV exportiert. Tatsächlich lassen sich kleinere Unterschiede zwischen den Einschätzungen der unterschiedlich trainierten Modelle feststellen. Das SVC-Modell mit dem kompletten Review-Datensatz als Trainings-Material scheint geringfügig bessere Entscheidungen zu treffen.\n",
    "Dies ist hier im nächsten Schritt statistisch zu zeigen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7c593",
   "metadata": {},
   "source": [
    "Die Güte des \"alten\" Models bleibt unverändert:\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       0.79      0.60      0.68       128\n",
    "               1       0.93      0.97      0.95       707\n",
    "\n",
    "        accuracy                           0.91       835\n",
    "       macro avg       0.86      0.79      0.82       835\n",
    "    weighted avg       0.91      0.91      0.91       835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db99fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_of_x = calibrated_classifier.predict(X_train_tfidf)\n",
    "prediction_of_x = classifier.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(german_review_data.positive, prediction_of_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52bd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(max_df = 0.3, min_df = 7, ngram_range = (1, 2))), ('clf', SVC(kernel = 'sigmoid'))])\n",
    "#As of now the GridSearch was useless, results are less accurate!\n",
    "#The tested GridParams should be modified max_iter is def not useful\n",
    "#Kernel and C should be further examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(german_review_data.clean_text, german_review_data.positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13321ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_new_pipeline = pipeline.predict(df.clean_comments)\n",
    "another_fresh_df = another_fresh_df.assign(prediction = prediction_new_pipeline)\n",
    "another_fresh_df\n",
    "#another_fresh_df.to_csv(\"ruegi_comments_new_pipeline_STEMMED_VERSION.csv\")\n",
    "another_fresh_df.to_csv(\"ruegi_comments_new_pipeline_STEMMED_VERSION_german.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': np.arange(0.3, 0.8, 0.1),\n",
    "    'vect__min_df': np.arange(1, 8, 1),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'vect__norm': ('l1', 'l2', None),\n",
    "    'clf__max_iter': (10, 50, 80),\n",
    "    'clf__kernel':('linear', 'rbf', 'sigmoid'),\n",
    "    'clf__C':[1, 10]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07758451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#grid_search = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1)\n",
    "#grid_search.fit(clean_review_data.clean_text, clean_review_data.positive)\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1399868",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = {'clf__C': 10, 'clf__kernel': 'linear', 'clf__max_iter': 80, 'vect__max_df': 0.3, 'vect__max_features': None, 'vect__min_df': 7, 'vect__ngram_range': (1, 2), 'vect__norm': 'l1', 'vect__use_idf': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e773a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
