{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aad4b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2c657c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"collection_A.pkl\", \"rb\") as f:\n",
    "    pickled_collection = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d248a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ruegi(lst):\n",
    "    tmp_lst = []\n",
    "    clean_lst = []\n",
    "    \n",
    "    for sublist in lst:\n",
    "        for item in sublist:\n",
    "            level_1 = re.sub(\"^[^\\\\n]*\\\\n\", \"\", item)\n",
    "            level_2 = re.sub(\"@.*?\\s\", \"\", level_1)\n",
    "            \n",
    "            if not re.search(\".*\\\\n\", level_2):\n",
    "                tmp_lst.append(level_2)\n",
    "            else:\n",
    "                matched_object = re.search(\".*\\\\n\", level_2)\n",
    "                matched_item = matched_object.group()\n",
    "                tmp_lst.append(matched_item)\n",
    "                \n",
    "    for comment in tmp_lst:\n",
    "        tmp_comment = re.sub(\"\\\\n\", \"\", comment)\n",
    "        clean_lst.append(tmp_comment)\n",
    "    \n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2dbf4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht l√§nger ab! üôåüèªü§© Holt euch den M√ºhlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil. üå≠üíö Mit etwas Gl√ºck zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein. üçÄ #R√ºgenwalderM√ºhle #M√ºhlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?ü§î‚òπ',\n",
       " 'Wie geilüî•üî•‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è',\n",
       " 'Wie macht ihr das eigentlich? ü§î Wie wir uns als traditioneller Wursthersteller f√ºr eine nachhaltige Zukunft und #Klimaneutralit√§t einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht. üåçüíö Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren. ‚ò∫Ô∏è Den Link zum Bericht findet ihr in der Bio! ‚úåüèª #R√ºgenwalderM√ºhle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? üòÄ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten ‚ù§ Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '‚ù§Ô∏è',\n",
       " 'Bitte vegan üå±',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. üò¢',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. üò¢',\n",
       " 'wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? üå± Mega Entwicklung. üëèüëè',\n",
       " 'mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tunüëèüëè',\n",
       " 'W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet üòÅ',\n",
       " 'Aufgepasst, liebe Social Media Welt! üåçüíö Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch. üöÄ Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise. ü§©üèÜ #R√ºgenwalderM√ºhle #M√ºhlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg √ºber vegetarisch?',\n",
       " 'Ich mag Euch f√ºr veggie, aber feiern w√ºrde ich Euch f√ºr vegan. Bekommt Ihr das hin? ü§©üí™üí™üí™',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_clean_lst = clean_ruegi(pickled_collection)\n",
    "a_clean_lst[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386b712",
   "metadata": {},
   "source": [
    "## Alternative Kommentarliste:\n",
    "\n",
    "Wenn das Topic Modeling keine sinnvollen Ergebnisse liefert, kann folgende Liste versuchsweise verwendet werden.\n",
    "Es wurden Einzelbeitr√§ge (also mit hoher Wahrscheinlichkeit Beitr√§ge, die entweder keine Benutzerantworten enthalten oder - wenn der Initialbeitrag des Autors fehlt - nur eine Antwort enthalten und somit eine geringe Relevanz aufweisen) entfernt.\n",
    "Sollte auch dies nicht zu aussagekr√§ftigten Ergebnissen f√ºhren, k√∂nnte die Originalliste wiederum um Beitr√§ge mit wenigen Antworten gefiltert werden (z.B. weniger als 5 Antworten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "264746ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['isa__90__\\nUnd wenn man kein tiktok hat?ü§î‚òπ\\n1 TagGef√§llt 2 MalAntworten',\n",
       "  'bentj_07\\nWie geilüî•üî•‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\\n1 TagAntworten'],\n",
       " ['sebastianpink96\\nDann mal weg mit dem Fleisch\\n1 Wo.Gef√§llt 13 MalAntworten',\n",
       "  'thinkvegande\\nWann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? üòÄ\\n1 Wo.Gef√§llt 33 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gef√§llt 1 MalAntworten',\n",
       "  'nina_joh93\\nGanz auf Fleisch verzichten ‚ù§ Ihr macht das so genial mit den Veggie Produkten!\\n1 Wo.Gef√§llt 17 MalAntworten',\n",
       "  'tascha4868\\n‚ù§Ô∏è\\n6 TageGef√§llt 1 MalAntworten',\n",
       "  'sab_koe\\nBitte vegan üå±\\n6 TageGef√§llt 6 MalAntworten',\n",
       "  'bentj_07\\nIch liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis\\n1 Wo.Gef√§llt 5 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. üò¢\\n6 TageGef√§llt 1 MalAntworten',\n",
       "  'veganumona\\nSchaut mal das video von offen und ehrlich bei Youtube. üò¢\\n6 TageAntworten',\n",
       "  'curious.dev\\n@ruegenwaldermuehle wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte? üå± Mega Entwicklung. üëèüëè\\n1 Wo.Gef√§llt 9 MalAntworten',\n",
       "  'succilady\\n@ruegenwaldermuehle mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tunüëèüëè\\n6 TageGef√§llt 5 MalAntworten',\n",
       "  'jaundiced_yellow\\n@ruegenwaldermuehle W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet üòÅ\\n1 Wo.Antworten']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []\n",
    "for sublist in pickled_collection:\n",
    "    if len(sublist) > 1:\n",
    "        new_list.append(sublist)\n",
    "new_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e348148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11076"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_clean_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "07643ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thanks to https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "\n",
    "def deEmojify(lst):\n",
    "    clean_lst = []\n",
    "    for item in lst:\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\n",
    "                                    \"]+\", flags = re.UNICODE)\n",
    "        tmp_item = regrex_pattern.sub(r'',item)\n",
    "        clean_lst.append(tmp_item)\n",
    "    return clean_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbc8c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ihr wollt gewinnen? Dann wartet nicht l√§nger ab!  Holt euch den M√ºhlen Snack, zeigt uns eure Snackmomente und nehmt an der #snackveggie Challenge auf TikTok teil.  Mit etwas Gl√ºck zieht schon bald ein neues E-Bike, eine Playstation 5 oder ein anderer toller Preis bei euch ein.  #R√ºgenwalderM√ºhle #M√ºhlenSnack #snackveggie #Challenge #TikTok',\n",
       " 'Und wenn man kein tiktok hat?',\n",
       " 'Wie geil',\n",
       " 'Wie macht ihr das eigentlich?  Wie wir uns als traditioneller Wursthersteller f√ºr eine nachhaltige Zukunft und #Klimaneutralit√§t einsetzen, zeigen wir euch in unserem #Nachhaltigkeitsbericht.  Wir freuen uns, wenn ihr euch die Zeit nehmt, reinzulesen und uns bei Fragen zu kontaktieren.  Den Link zum Bericht findet ihr in der Bio!  #R√ºgenwalderM√ºhle',\n",
       " 'Dann mal weg mit dem Fleisch',\n",
       " 'Wann gibt es endlich den veganen Schinken aus den veganen Cordon Bleu separat? ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Ganz auf Fleisch verzichten  Ihr macht das so genial mit den Veggie Produkten!',\n",
       " '',\n",
       " 'Bitte vegan ',\n",
       " 'Ich liebe alle eure Veggie Produkte. Wenn ihr so weiter macht dann muss nie wieder jemand irgendwas anderes essen. #heildeerruegenwaldermuehle #eurewurstistgotteswerk #ruegis',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'Schaut mal das video von offen und ehrlich bei Youtube. ',\n",
       " 'wenn ihr euch f√ºr Menschen, Tiere und die Umwelt engagiert, veganisiert ihr jetzt endlich alle restlichen Tierqualprodukte?  Mega Entwicklung. ',\n",
       " 'mich w√ºrde es eher interessieren, wann ihr das mit diesem \"traditionellen tierischem\" endlich aufh√∂rt und statt dessen auf rein vegetarisch - allerdings noch besser - \" rein vegan\" umstellt, denn dass dies bei euch mehr Gewinn einf√§hrt, wird ja durch die Zahlen immer wieder belegt und somit k√∂nnt ihr dann tats√§chlich mehr f√ºr das Klima, unsere gemeinsame Umwelt, unseren Nachkommen und das sinnlose t√∂ten von Lebewesen tun',\n",
       " 'W√ºrde mich auch freuen, wenn ihr mal in meine DMs sliden w√ºrdet ',\n",
       " 'Aufgepasst, liebe Social Media Welt!  Ab sofort findet ihr uns auch auf TikTok. Wir warten nicht lange und starten gemeinsam mit euch bei unserer #snackveggie Challenge direkt voll durch.  Schaut auf TikTok vorbei, nehmt an der Challenge teil und sichert euch die Chance auf tolle Preise.  #R√ºgenwalderM√ºhle #M√ºhlenSnack #TikTok',\n",
       " 'Warum nicht vegan? Wozu immer erst der Umweg √ºber vegetarisch?',\n",
       " 'Ich mag Euch f√ºr veggie, aber feiern w√ºrde ich Euch f√ºr vegan. Bekommt Ihr das hin? ',\n",
       " 'Wo kann ich kaufen ? Lidl hat es nicht']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_ems = deEmojify(a_clean_lst)\n",
    "without_ems[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ceaf2693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>242 Wo.Gef√§llt 1 MalAntworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11076 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...\n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...\n",
       "11074                      242 Wo.Gef√§llt 1 MalAntworten\n",
       "11075                            Herzlichen Gl√ºckqunsch \n",
       "\n",
       "[11076 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'comments': without_ems})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64e1328c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...\n",
       "1                          Und wenn man kein tiktok hat?\n",
       "2                                               Wie geil\n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...\n",
       "4                           Dann mal weg mit dem Fleisch\n",
       "...                                                  ...\n",
       "11069  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...\n",
       "11071                             Legga 288 Wo.Antworten\n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...\n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...\n",
       "11075                            Herzlichen Gl√ºckqunsch \n",
       "\n",
       "[8896 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bde4595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jwlmsn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aa801a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "decd8a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr wollt gewinnen? Dann wartet nicht l√§nger a...</td>\n",
       "      <td>wollt gewinn wartet nicht lang ab holt muhl sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Und wenn man kein tiktok hat?</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wie geil</td>\n",
       "      <td>geil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie macht ihr das eigentlich?  Wie wir uns als...</td>\n",
       "      <td>macht eigent traditionell wurstherstell nachha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dann mal weg mit dem Fleisch</td>\n",
       "      <td>fleisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11069</th>\n",
       "      <td>So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...</td>\n",
       "      <td>leck fruhstuck ausseh schinkenspick ruegenwald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11071</th>\n",
       "      <td>Legga 288 Wo.Antworten</td>\n",
       "      <td>legga antwort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...</td>\n",
       "      <td>muhl wurd eroffnet muhl wahrzeich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11073</th>\n",
       "      <td>War super euer m√ºhlenfest ;) wir waren ja den ...</td>\n",
       "      <td>sup muhlenf ja samstag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11075</th>\n",
       "      <td>Herzlichen Gl√ºckqunsch</td>\n",
       "      <td>herzlich gluckqunsch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8896 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "0      Ihr wollt gewinnen? Dann wartet nicht l√§nger a...   \n",
       "1                          Und wenn man kein tiktok hat?   \n",
       "2                                               Wie geil   \n",
       "3      Wie macht ihr das eigentlich?  Wie wir uns als...   \n",
       "4                           Dann mal weg mit dem Fleisch   \n",
       "...                                                  ...   \n",
       "11069  So muss leckeres Fr√ºhst√ºck aussehen :-) #Schin...   \n",
       "11071                             Legga 288 Wo.Antworten   \n",
       "11072  Mai 2013: Die M√ºhle wurde er√∂ffnet! :-) #M√ºhle...   \n",
       "11073  War super euer m√ºhlenfest ;) wir waren ja den ...   \n",
       "11075                            Herzlichen Gl√ºckqunsch    \n",
       "\n",
       "                                          clean_comments  \n",
       "0      wollt gewinn wartet nicht lang ab holt muhl sn...  \n",
       "1                                                 tiktok  \n",
       "2                                                   geil  \n",
       "3      macht eigent traditionell wurstherstell nachha...  \n",
       "4                                                fleisch  \n",
       "...                                                  ...  \n",
       "11069     leck fruhstuck ausseh schinkenspick ruegenwald  \n",
       "11071                                      legga antwort  \n",
       "11072                  muhl wurd eroffnet muhl wahrzeich  \n",
       "11073                             sup muhlenf ja samstag  \n",
       "11075                               herzlich gluckqunsch  \n",
       "\n",
       "[8896 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "\n",
    "stopwords_custom = ['andere', 'der', 'weil', 'wieder', 'zwar', 'oder', 'so', 'solcher', 'unseres', 'doch', 'ihren', 'vor', 'ihm', 'hatte', 'muss', 'selbst', 'eurer', 'welchen', 'meine', 'was', 'werden', 'kann', 'einem', 'jedes', 'ihr', 'sie', 'sind', 'diesem', 'zu', 'jener', 'unser', 'sollte', 'manches', 'zur', 'diesen', 'allem', 'unserem', 'anderen', 'dieses', 'einen', 'hatten', 'einigem', 'hat', 'zwischen', 'zum', 'welche', 'dieser', 'nach', 'w√§hrend', 'wollte', 'bei', 'ich', 'dann', 'ihre', 'solchem', 'warst', 'das', 'meinen', 'sich', 'eure', 'einigen', 'deiner', 'keiner', 'da', 'meinem', 'k√∂nnte', 'seinen', 'dort', 'mein', 'wird', 'uns', 'am', 'derer', 'seine', 'er', 'da√ü', 'deines', 'w√ºrden', 'um', 'keines', 'musste', 'unsere', 'haben', 'weg', 'wo', 'wollen', 'dich', 'unter', 'in', 'ins', 'jeder', 'hier', 'von', 'dieselbe', 'dir', 'denn', 'diese', 'hab', 'indem', 'mit', 'einmal', 'allen', 'den', 'machen', 'ander', 'damit', 'durch', 'im', 'mich', 'dasselbe', 'euer', 'deinem', 'jenem', 'derselbe', 'dessen', 'alle', 'gewesen', 'aus', 'soll', 'jenen', 'welchem', 'anders', 'bin', 'bis', 'jene', 'solchen', 'du', 'ihres', 'demselben', 'als', 'will', 'wirst', 'war', 'jede', 'eures', 'dieselben', 'jedem', 'einige', 'eine', 'einiger', 'manche', 'seines', 'sein', 'denselben', 'noch', 'welcher', 'nur', 'mal', 'viel', 'ein', 'meiner', 'mancher', 'ihrer', 'desselben', 'ihrem', 'meines', 'dies', 'einer', 'jetzt', 'auch', 'f√ºr', 'wenn', 'solches', '√ºber', 'welches', 'ist', 'wie', 'es', 'anderm', 'deine', 'habe', 'wir', 'ohne', 'hin', 'dem', 'einiges', 'manchem', 'und', 'vom', 'w√ºrde', 'manchen', 'euch', 'solche', 'jenes', 'euren', 'aller', 'ihnen', 'eines', 'hinter', 'seinem', 'etwas', 'aber', 'kein', 'mir', 'dass', 'sondern', 'andern', 'anderes', 'unseren', 'dein', 'seiner', 'nun', 'jeden', 'anderer', 'man', 'weiter', 'sonst', 'keinem', 'alles', 'gegen', 'werde', 'bist', 'an', 'einig', 'ihn', 'auf', 'keine', 'des', 'eurem', 'derselben', 'anderem', 'dazu', 'k√∂nnen', 'waren', 'deinen', 'keinen', 'also', 'ob', 'die', 'une', 'retenter', 'gr', 'grad', 'tastes', 'texture', 'de', 'weekly', 'v√©g√©tal', 'break', 'bang', 'par', 'wheaty', 'pan', 'that', 'mai', 'hungry', 'additionally', 'after', 'cuisson', 'palette', 've', 'veau', 'vater', 'doutes', 'buns', 'ein', 'per', 'charcuteries', 'grad', 'haut', 'big', 'celle', 'certainement', 'contre', 'convincing', 'maie']\n",
    "\n",
    "def clean_text(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    stopwords_removed = [word for word in text_lower if word not in stopwords_custom]\n",
    "    stemmed_words = [stemmer.stem(word) for word in stopwords_removed]\n",
    "    filtered = \" \".join(stemmed_words)\n",
    "    return filtered\n",
    "\n",
    "df = df.assign(clean_comments = df[\"comments\"].apply(lambda row: clean_text(row)))\n",
    "#Making a copy for later use:\n",
    "fresh_df = df.copy()\n",
    "another_fresh_df = df.copy()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dca5a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = df[df.comments.str.contains(\"vegan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "927268be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wann gibt es endlich den veganen Schinken aus ...</td>\n",
       "      <td>wann gibt endlich vegan schink vegan cordon bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitte vegan</td>\n",
       "      <td>bitt vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wenn ihr euch f√ºr Menschen, Tiere und die Umwe...</td>\n",
       "      <td>mensch tier umwelt engagiert veganisiert endli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mich w√ºrde es eher interessieren, wann ihr das...</td>\n",
       "      <td>eher interessi wann traditionell tierisch endl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Warum nicht vegan? Wozu immer erst der Umweg √º...</td>\n",
       "      <td>warum nicht vegan wozu imm erst umweg vegetar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Ich finde es toll, dass ihr nun auch vegan und...</td>\n",
       "      <td>find toll vegan vegetar produziert helft sehr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>K√∂nnt ihr noch mehr raus bringen veggi und veg...</td>\n",
       "      <td>konnt mehr raus bring veggi vegan freund ess i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>Deshalb lebe ich seit einiger Zeit jetzt auch ...</td>\n",
       "      <td>deshalb leb seit zeit vegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>Macht doch bittebittebitte eure vegetarische W...</td>\n",
       "      <td>macht bittebittebitt vegetar wurst vegan war s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Und Mettwurst als vegetarische bzw. vegane Alt...</td>\n",
       "      <td>mettwurst vegetar bzw vegan alternativ war sup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "5      Wann gibt es endlich den veganen Schinken aus ...   \n",
       "9                                           Bitte vegan    \n",
       "13     wenn ihr euch f√ºr Menschen, Tiere und die Umwe...   \n",
       "14     mich w√ºrde es eher interessieren, wann ihr das...   \n",
       "17     Warum nicht vegan? Wozu immer erst der Umweg √º...   \n",
       "...                                                  ...   \n",
       "10727  Ich finde es toll, dass ihr nun auch vegan und...   \n",
       "10728  K√∂nnt ihr noch mehr raus bringen veggi und veg...   \n",
       "10761  Deshalb lebe ich seit einiger Zeit jetzt auch ...   \n",
       "10801  Macht doch bittebittebitte eure vegetarische W...   \n",
       "10802  Und Mettwurst als vegetarische bzw. vegane Alt...   \n",
       "\n",
       "                                          clean_comments  \n",
       "5      wann gibt endlich vegan schink vegan cordon bl...  \n",
       "9                                             bitt vegan  \n",
       "13     mensch tier umwelt engagiert veganisiert endli...  \n",
       "14     eher interessi wann traditionell tierisch endl...  \n",
       "17         warum nicht vegan wozu imm erst umweg vegetar  \n",
       "...                                                  ...  \n",
       "10727  find toll vegan vegetar produziert helft sehr ...  \n",
       "10728  konnt mehr raus bring veggi vegan freund ess i...  \n",
       "10761                        deshalb leb seit zeit vegan  \n",
       "10801  macht bittebittebitt vegetar wurst vegan war s...  \n",
       "10802     mettwurst vegetar bzw vegan alternativ war sup  \n",
       "\n",
       "[1857 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65bb77",
   "metadata": {},
   "source": [
    "## Klassifizierungsversuch mithilfe des trainierten SVC-Modells\n",
    "\n",
    "1. \"clean_comments\" sind die neuen Test-Daten\n",
    "2. predict-Funktion des Models zeigt Ergebnis der Klassifizierung\n",
    "3. Ausgabe der sortierten \"clean_comments\" (positiv/negativ)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2b0bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "with open(\"trained_pipeline.pkl\", \"rb\") as f:\n",
    "    trained_pipeline = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1da119cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trained_pipeline.predict(vegan[\"clean_comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7815ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = vegan.assign(prediction = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95022025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wann gibt es endlich den veganen Schinken aus ...</td>\n",
       "      <td>wann gibt endlich vegan schink vegan cordon bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bitte vegan</td>\n",
       "      <td>bitt vegan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wenn ihr euch f√ºr Menschen, Tiere und die Umwe...</td>\n",
       "      <td>mensch tier umwelt engagiert veganisiert endli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mich w√ºrde es eher interessieren, wann ihr das...</td>\n",
       "      <td>eher interessi wann traditionell tierisch endl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Warum nicht vegan? Wozu immer erst der Umweg √º...</td>\n",
       "      <td>warum nicht vegan wozu imm erst umweg vegetar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>Ich finde es toll, dass ihr nun auch vegan und...</td>\n",
       "      <td>find toll vegan vegetar produziert helft sehr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>K√∂nnt ihr noch mehr raus bringen veggi und veg...</td>\n",
       "      <td>konnt mehr raus bring veggi vegan freund ess i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10761</th>\n",
       "      <td>Deshalb lebe ich seit einiger Zeit jetzt auch ...</td>\n",
       "      <td>deshalb leb seit zeit vegan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>Macht doch bittebittebitte eure vegetarische W...</td>\n",
       "      <td>macht bittebittebitt vegetar wurst vegan war s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Und Mettwurst als vegetarische bzw. vegane Alt...</td>\n",
       "      <td>mettwurst vegetar bzw vegan alternativ war sup</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1857 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  \\\n",
       "5      Wann gibt es endlich den veganen Schinken aus ...   \n",
       "9                                           Bitte vegan    \n",
       "13     wenn ihr euch f√ºr Menschen, Tiere und die Umwe...   \n",
       "14     mich w√ºrde es eher interessieren, wann ihr das...   \n",
       "17     Warum nicht vegan? Wozu immer erst der Umweg √º...   \n",
       "...                                                  ...   \n",
       "10727  Ich finde es toll, dass ihr nun auch vegan und...   \n",
       "10728  K√∂nnt ihr noch mehr raus bringen veggi und veg...   \n",
       "10761  Deshalb lebe ich seit einiger Zeit jetzt auch ...   \n",
       "10801  Macht doch bittebittebitte eure vegetarische W...   \n",
       "10802  Und Mettwurst als vegetarische bzw. vegane Alt...   \n",
       "\n",
       "                                          clean_comments  prediction  \n",
       "5      wann gibt endlich vegan schink vegan cordon bl...           1  \n",
       "9                                             bitt vegan           1  \n",
       "13     mensch tier umwelt engagiert veganisiert endli...           1  \n",
       "14     eher interessi wann traditionell tierisch endl...           0  \n",
       "17         warum nicht vegan wozu imm erst umweg vegetar           1  \n",
       "...                                                  ...         ...  \n",
       "10727  find toll vegan vegetar produziert helft sehr ...           1  \n",
       "10728  konnt mehr raus bring veggi vegan freund ess i...           1  \n",
       "10761                        deshalb leb seit zeit vegan           1  \n",
       "10801  macht bittebittebitt vegetar wurst vegan war s...           1  \n",
       "10802     mettwurst vegetar bzw vegan alternativ war sup           1  \n",
       "\n",
       "[1857 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0: negativ, 1: positiv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(vegan)\n",
    "display(\"0: negativ, 1: positiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2bcaec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_positive_predicted = vegan[vegan.prediction == 1]\n",
    "vegan_negative_predicted = vegan[vegan.prediction == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "926ca418",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan.to_csv(\"ruegi_vegan_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e9c2af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_prediction = trained_pipeline.predict(df[\"clean_comments\"])\n",
    "df = df.assign(prediction = complete_df_prediction)\n",
    "df.to_csv(\"ruegi_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fe2f3",
   "metadata": {},
   "source": [
    "## Test: Das SVC-Modell wird mit dem kompletten Review-Datensatz trainiert und mit dem neuen (R√ºgenwalder) Datensatz getestet\n",
    "\n",
    "Der TF-IDF-Vectorizer von Scikit-Learn wird als erstes an den kompletten (bereinigten) Text-Datensatz angepasst. Die Spalte \"clean_text\" wird in eine Sparse-Matrix √ºberf√ºhrt, der SVC-Classifier mit den in Vektoren √ºberf√ºhrten Kommentaren und den Kommentaren selbst (also hier \"Labels\" als tokinisierte Textbausteine) trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac84a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuckergehalt</td>\n",
       "      <td>1</td>\n",
       "      <td>zuckergehalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geh√∂ren in jeden veganen Haushalt!</td>\n",
       "      <td>1</td>\n",
       "      <td>gehor vegan haushalt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schon ein Klassiker...</td>\n",
       "      <td>1</td>\n",
       "      <td>schon klassik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "      <td>sup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super!</td>\n",
       "      <td>1</td>\n",
       "      <td>sup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8341</th>\n",
       "      <td>Geschmack ist pappig und maggiartig, die Konsi...</td>\n",
       "      <td>0</td>\n",
       "      <td>geschmack pappig maggiart konsistenz klebrig p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>Da scheiden sich sie Geister. So meiner ist er...</td>\n",
       "      <td>0</td>\n",
       "      <td>scheid geist nicht probi test liebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>Richtig lecker, aber leider zu trocken. Da geh...</td>\n",
       "      <td>0</td>\n",
       "      <td>richtig leck leid trock geht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>Die Muffins haben zwar eine guten Preis, waren...</td>\n",
       "      <td>0</td>\n",
       "      <td>muffin gut preis trock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>Die helle Muffin Variante mit Schokost√ºcken vo...</td>\n",
       "      <td>0</td>\n",
       "      <td>hell muffin variant schokostuck veganz leck sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8302 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  positive  \\\n",
       "0                                          Zuckergehalt         1   \n",
       "1                    Geh√∂ren in jeden veganen Haushalt!         1   \n",
       "2                                Schon ein Klassiker...         1   \n",
       "3                                                Super!         1   \n",
       "4                                                Super!         1   \n",
       "...                                                 ...       ...   \n",
       "8341  Geschmack ist pappig und maggiartig, die Konsi...         0   \n",
       "8342  Da scheiden sich sie Geister. So meiner ist er...         0   \n",
       "8343  Richtig lecker, aber leider zu trocken. Da geh...         0   \n",
       "8344  Die Muffins haben zwar eine guten Preis, waren...         0   \n",
       "8345  Die helle Muffin Variante mit Schokost√ºcken vo...         0   \n",
       "\n",
       "                                             clean_text  \n",
       "0                                          zuckergehalt  \n",
       "1                                  gehor vegan haushalt  \n",
       "2                                         schon klassik  \n",
       "3                                                   sup  \n",
       "4                                                   sup  \n",
       "...                                                 ...  \n",
       "8341  geschmack pappig maggiart konsistenz klebrig p...  \n",
       "8342                scheid geist nicht probi test liebe  \n",
       "8343                       richtig leck leid trock geht  \n",
       "8344                             muffin gut preis trock  \n",
       "8345  hell muffin variant schokostuck veganz leck sa...  \n",
       "\n",
       "[8302 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"cleaned_training_data.pkl\", \"rb\") as f:\n",
    "    clean_review_data = pickle.load(f)\n",
    "clean_review_data[\"text\"].replace(\"\", np.nan, inplace=True)\n",
    "clean_review_data = clean_review_data[clean_review_data[\"text\"].notna()]\n",
    "#new_review_data = clean_review_data\n",
    "clean_review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c1512e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_letters(words):\n",
    "    re_ascii = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
    "    words = re.sub(re_ascii, \" \", words)\n",
    "    tokenized = word_tokenize(words)\n",
    "    text_lower = [token.lower() for token in tokenized]\n",
    "    filtered = \" \".join(text_lower)\n",
    "    return filtered\n",
    "\n",
    "clean_review_data = clean_review_data.assign(langdetect = clean_review_data[\"text\"].apply(lambda row: remove_non_letters(row)))\n",
    "clean_review_data[\"langdetect\"].replace(\"\", np.nan, inplace=True)\n",
    "clean_review_data = clean_review_data[clean_review_data[\"langdetect\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e670ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "detect(clean_review_data[\"text\"][888])\n",
    "german_review_data = clean_review_data[clean_review_data[\"langdetect\"].apply(lambda row: detect(row) == \"de\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_cp_german_review_data = german_review_data.copy()\n",
    "display(clean_review_data.info())\n",
    "display(german_review_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=0.3)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(german_review_data[\"clean_text\"])\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "#classifier = LinearSVC()\n",
    "#calibrated_classifier = CalibratedClassifierCV(classifier)\n",
    "classifier.fit(X_train_tfidf, german_review_data.positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39ef9f",
   "metadata": {},
   "source": [
    "Wichtig ist hier darauf zu achten, den TF-IDF-Vectorizer nicht mit dem neuen Datensatz zu fitten, sondern vielmehr die neuen Kommentare mithilfe des Vektorisierers in eine f√ºr das Modell lesbare Zahlenmatrix zu √ºberf√ºhren - und zwar **mithilfe** des bereits angepassten Vektorisieres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ec7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ruegi = tfidf_vectorizer.transform(df.clean_comments)\n",
    "display(X_test_ruegi.shape)\n",
    "\n",
    "prediction_model_only = classifier.predict(X_test_ruegi)\n",
    "#prediction_model_only = calibrated_classifier.predict(X_test_ruegi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_df = fresh_df.assign(prediction = prediction_model_only)\n",
    "display(fresh_df)\n",
    "display(\"0: negativ, 1: positiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline.csv\")\n",
    "fresh_df.to_csv(\"ruegi_comments_pred_w-o_pipeline_SVC_STEMMED_VERSION.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed0be2",
   "metadata": {},
   "source": [
    "Zum einfacheren Vergleich werden die kategorisierten Datens√§tze als CSV exportiert. Tats√§chlich lassen sich kleinere Unterschiede zwischen den Einsch√§tzungen der unterschiedlich trainierten Modelle feststellen. Das SVC-Modell mit dem kompletten Review-Datensatz als Trainings-Material scheint geringf√ºgig bessere Entscheidungen zu treffen.\n",
    "Dies ist hier im n√§chsten Schritt statistisch zu zeigen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f7c593",
   "metadata": {},
   "source": [
    "Die G√ºte des \"alten\" Models bleibt unver√§ndert:\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               0       0.79      0.60      0.68       128\n",
    "               1       0.93      0.97      0.95       707\n",
    "\n",
    "        accuracy                           0.91       835\n",
    "       macro avg       0.86      0.79      0.82       835\n",
    "    weighted avg       0.91      0.91      0.91       835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db99fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_of_x = calibrated_classifier.predict(X_train_tfidf)\n",
    "prediction_of_x = classifier.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(german_review_data.positive, prediction_of_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52bd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer(max_df = 0.3, min_df = 7, ngram_range = (1, 2))), ('clf', SVC(kernel = 'sigmoid'))])\n",
    "#As of now the GridSearch was useless, results are less accurate!\n",
    "#The tested GridParams should be modified max_iter is def not useful\n",
    "#Kernel and C should be further examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(german_review_data.clean_text, german_review_data.positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13321ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_new_pipeline = pipeline.predict(df.clean_comments)\n",
    "another_fresh_df = another_fresh_df.assign(prediction = prediction_new_pipeline)\n",
    "another_fresh_df\n",
    "#another_fresh_df.to_csv(\"ruegi_comments_new_pipeline_STEMMED_VERSION.csv\")\n",
    "another_fresh_df.to_csv(\"ruegi_comments_new_pipeline_STEMMED_VERSION_german.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vect__max_df': np.arange(0.3, 0.8, 0.1),\n",
    "    'vect__min_df': np.arange(1, 8, 1),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'vect__norm': ('l1', 'l2', None),\n",
    "    'clf__max_iter': (10, 50, 80),\n",
    "    'clf__kernel':('linear', 'rbf', 'sigmoid'),\n",
    "    'clf__C':[1, 10]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07758451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#grid_search = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1)\n",
    "#grid_search.fit(clean_review_data.clean_text, clean_review_data.positive)\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1399868",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_results = {'clf__C': 10, 'clf__kernel': 'linear', 'clf__max_iter': 80, 'vect__max_df': 0.3, 'vect__max_features': None, 'vect__min_df': 7, 'vect__ngram_range': (1, 2), 'vect__norm': 'l1', 'vect__use_idf': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e773a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
